---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

width
1. freq words
2. freq words usa vs ind
depth
3. vad
4. vad w diff factors
plan: 
1. finish with 4
2. improve visualization method

From a psychological angle

```{r load libraries, warning=FALSE, message=FALSE}
library(ggplot2)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny) 
```

```{r}
setwd("~/GitHub/Fall2018-Proj1-JudyCom/output")
data = read.csv("processed_moments.csv",as.is = TRUE)
df = data[,c(3,9,10,11)]
category = as.factor(df$predicted_category)
n = nrow(data)
ind_3m = which(df$reflection == "3m")
data_3m = df[ind_3m,]
ind_24h = which(df$reflection == "24h")
data_24h = df[ind_24h,]

n_3m = nrow(data_3m)
n_24h = nrow(data_24h)
# cat_freq = table(category)/n
# cat_freq
# barplot(cat_freq, main = "Category Frequency")
```
category bar plot, all, 24h, 3m
```{r}

ggplot(data = data)+
  geom_bar(aes(x=predicted_category))+
  labs(title = "Predicted Category Frequency", x = "Category", y = "Frequency")
ggplot(data = data_24h)+
  geom_bar(aes(x=predicted_category))+
  labs(title = "Predicted Category Frequency: 24h", x = "Category", y = "Frequency")
ggplot(data = data_3m)+
  geom_bar(aes(x=predicted_category))+
  labs(title = "Predicted Category Frequency: 3m", x = "Category", y = "Frequency")
```

find word frequency
```{r}
txt = as.vector(df$text)
txt1 = paste(txt, collapse = " ")

wd = strsplit(txt1, split = " ")[[1]]
# head(wd,5)
wd_df = as.data.frame(wd)
wd_count = sort(table(wd)/length(wd), decreasing = TRUE)
#wd_count_df = as.data.frame(wd_count)
ct10 = head(wd_count,10)
wd_df
rel_freq30 = 
wd_fac = as.factor(wd)
length(levels(wd_fac))
length(wd)

barplot(ct10, xlab = "Words", ylab = "Relative Frequency", main = "Most frequent words")
#found: surprise in a good way

```

verb exploration
```{r}
stnc = data$cleaned_hm
# stnc1 = paste(stnc, collapse = " ")
found_stnc = stnc[grep("found", stnc)]
found_line = txt[grep("found", txt)]
#surprise
watched_stnc = stnc[grep("watched", stnc)]
watched_line = txt[grep("watched", txt)]
played_stnc = stnc[grep("played", stnc)]
watched_line = txt[grep("watched", txt)]
```

demographic
```{r}
d
```

vad
valence (the pleasantness of a stimulus): 
arousal (the intensity of emotion provoked by a stimulus),
dominance (the degree of control exerted by a stimulus) 

```{r}
setwd("~/GitHub/Fall2018-Proj1-JudyCom/data")
vad = read.csv("vad.csv", as.is = TRUE)
vad = na.omit(vad[,c("hmid","valency", "arousal","dominance")])
vad_mean = colMeans(vad, na.rm = TRUE)


# plot(vad$valency,vad$arousal)
# plot(vad$valency,vad$dominance)
# plot(vad$dominance,vad$arousal)
vad_mean

ggplot(data=vad)+
  geom_point(aes(x=valency, y=dominance), size =0.1)+
  stat_smooth(aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)

ggplot(data=vad)+
  geom_point(aes(x=valency, y=arousal), size =0.1)+
  stat_smooth(aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)

reg = lm(arousal~valency+I((valency)^2), data = vad)
summary(reg)

#min valency just a joke: mention
#escape from a worse status: happiness is relative - lower your expectancy
min_v_hmid = as.numeric(vad[order(vad$valency, decreasing = FALSE)[1:30],]$hmid)
min_v_stnc = NULL
for (hm in min_v_hmid){
  print (data[data$hmid == hm, ]$original_hm)
}

min_a_hmid = as.numeric(vad[order(vad$arousal, decreasing = FALSE)[1:30],]$hmid)
min_a_stnc = NULL
for (hm in min_a_hmid){
  print (data[data$hmid == hm, ]$original_hm)
}

# full = merge(data[,c("hmid","original_hm")],vad)
```

```{r}
setwd("~/GitHub/Fall2018-Proj1-JudyCom/output")
hm_data <- read_csv("processed_moments.csv")

urlfile_vad<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/vad.csv'
vad_data <- read_csv(urlfile_vad)

hm_data <- hm_data %>%
  inner_join(vad_data, by = "hmid")%>%
    select(wid,
           hmid,
           reflection_period,
           original_hm,
           valency,
           arousal,
           text,
           predicted_category)

urlfile_demo<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile_demo)

hm_data <- hm_data %>%
  inner_join(demo_data, by = "wid")%>%
    select(wid,
           hmid,
           original_hm,
           valency,
           arousal,
           gender,
           marital,
           parenthood,
           reflection_period,
           age,
           country,
           text,
           predicted_category)%>%
  filter(gender %in% c("m", "f")) %>%
  filter(marital %in% c("single", "married")) %>%
  filter(parenthood %in% c("n", "y")) %>%
  filter(reflection_period %in% c("24h", "3m")) %>%
  mutate(reflection_period = fct_recode(reflection_period,
                                        months_3 = "3m", hours_24 = "24h"))
```

country
comparison: most freq words, category btwn usa & ind
usa: more outgoing, active, achievement
```{r}
count_cty = sort(table(hm_data$country), decreasing = TRUE)
#most are from usa and indian
us_data = hm_data[]

usa_data = hm_data[which(hm_data$country == "USA"),]
ind_data = hm_data[which(hm_data$country == "IND"),]

# n_3m = nrow(data_3m)
# n_24h = nrow(data_24h)
# 
# ggplot(data = usa_data)+
#   geom_bar(aes(x=predicted_category))+
#   labs(title = "Predicted Category Frequency: 24h", x = "Category", y = "Frequency")

txt = as.vector(usa_data$text)
txt1 = paste(txt, collapse = " ")

wd = strsplit(txt1, split = " ")[[1]]
# head(wd,5)
wd_df = as.data.frame(wd)
wd_count = sort(table(wd), decreasing = TRUE)
#wd_count_df = as.data.frame(wd_count)
ct10 = head(wd_count,10)
df10 = as.data.frame(rep(names(ct10),ct10))
names(df10) = "words"
df10$words <- factor(df10$words, levels = names(ct10))
ggplot(data=df10)+
  geom_bar(aes(words))

# barplot(ct10, xlab = "Words", ylab = "Relative Frequency", main = " USA Most frequent words")

txt = as.vector(ind_data$text)
txt1 = paste(txt, collapse = " ")

wd = strsplit(txt1, split = " ")[[1]]
# head(wd,5)
wd_df = as.data.frame(wd)
wd_count = sort(table(wd), decreasing = TRUE)
#wd_count_df = as.data.frame(wd_count)
ct10 = head(wd_count,10)
df10 = as.data.frame(rep(names(ct10),ct10))
names(df10) = "words"
df10$words <- factor(df10$words, levels = names(ct10))
ggplot(data=df10)+
  geom_bar(aes(words))

ggplot(data = usa_data)+
  geom_bar(aes(x=predicted_category))+
  labs(title = "Predicted Category Frequency: USA", x = "Category", y = "Frequency")
ggplot(data = ind_data)+
  geom_bar(aes(x=predicted_category))+
  labs(title = "Predicted Category Frequency: ind", x = "Category", y = "Frequency")



# barplot(ct10, xlab = "Words", ylab = "Relative Frequency", main = " IND Most frequent words")
```

senselabel: n v adj/supersense

Happiness is simple, transient, relative, sometimes unexpected.
