arousal,
dominance)%>%
filter(country %in% c("USA","IND"))
ggplot(country_vad,aes(x=country, y = valency, fill = country))+
geom_boxplot(notch = FALSE, outlier.colour="#CC6600")+
scale_fill_manual(name = "", values = c("#00BFFF", "#66FF00")) +
theme(panel.background = element_rect(fill = 'white' )) +
ggtitle(paste("Comparing Valency between Country"))
country_vad = hm_data%>%
select(country,
valency,
arousal,
dominance)%>%
filter(country %in% c("USA","IND"))
ggplot(country_vad,aes(x=country, y = valency, fill = country))+
geom_boxplot(notch = FALSE, outlier.colour="#CC6600")+
scale_fill_manual(name = "", values = c("#00BFFF", "#66FF00")) +
theme(panel.background = element_rect(fill = 'white' )) +
ggtitle(paste("Comparing Valency between Country"))
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
p1 = ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
p2 = ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggarrange(p1, p2, common.legend=FALSE,legend = 'right', nrow=1, ncol=2)
p1 = ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
p2 = ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggarrange(p1, p2, common.legend=FALSE, legend = 'right', nrow=1, ncol=2)
p1 = ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
p2 = ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggarrange(p1, p2, common.legend=FALSE, legend = 'right', nrow=2, ncol=1)
p1 = ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
p2 = ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggarrange(p1, p2, common.legend=FALSE, legend = 'right', nrow=2, ncol=1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>3),aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>3),aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>3),aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>4),aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>4 & valency <8),aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>4 & valency <8),aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>4 & valency <8),aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
country_vad = hm_data%>%
select(country,
valency,
arousal,
dominance)%>%
filter(country %in% c("USA","IND"))
ggplot(country_vad,aes(x=country, y = valency, fill = country))+
geom_boxplot(notch = FALSE, outlier.colour="#CC6600")+
scale_fill_manual(name = "", values = c("#00BFFF", "#66FF00")) +
theme(panel.background = element_rect(fill = 'white' )) +
ggtitle(paste("Comparing Valency between Country"))
# vad_data <- read_csv(urlfile2)
vad_data = data.frame(vad_data)
vad_data = cbind(vad_data[,1:2],vad_data$arousal,vad_data$dominance)
head(vad_data)
vad_data <- read_csv(urlfile2)
# vad_data <- read_csv(urlfile2)
vad_data = data.frame(vad_data)
vad_data = cbind(vad_data[,1:2],vad_data$arousal,vad_data$dominance)
vad_ori = stats::na.omit(vad_data)
vad = vad_ori
vad[,2:4]= scale(vad_ori[,2:4])
# Determine number of clusters
hmid_vad = vad[,1]
va = vad[,2:3]
# K-Means Cluster Analysis
set.seed(1)
fit <- kmeans(va, 3) # 3 cluster solution
km_vad <- data.frame(vad_ori, fit$cluster)
names(km_vad)[3:5] = c("arousal","dominance","subjective_group")
km_vad[which(km_vad[,5]==2),5]=0
km_vad[which(km_vad[,5]==1),5]=2
km_vad[which(km_vad[,5]==0),5]=1
head(km_vad)
km_vad$subjective_group = as.factor(km_vad$subjective_group)
# head(va)
# plot(km_vad[,2:3], col = km_vad$cluster)
ggplot(data = km_vad,aes(x=valency,y=arousal))+
geom_point()+
geom_point(aes(colour = subjective_group))
# km_vad
vad_age = data.frame(hm_data)[,-c(13,14,15)]%>%
inner_join(km_vad, by="hmid")%>%
select(hmid,
age,
valency,
arousal,
dominance,
subjective_group)
vad_age$age = as.numeric(vad_age$age)
vad_age = stats::na.omit(vad_age)
vad_age = vad_age[vad_age$age < 100,]
ggplot(vad_age,aes(x=subjective_group, y = age))+
geom_violin(aes(fill = subjective_group))
ma = mean(hm_data$arousal, na.rm = TRUE)
ma
head(vad_age)
mda = median(hm_data$arousal, na.rm = TRUE)
mda
vad_age$arousal_level = as.factor(ifelse(arousal>median(hm_data$arousal, na.rm = TRUE), "high arousal", "low arousal"))
vad_age$arousal_level = as.factor(ifelse(vad_age$arousal>median(vad_age$arousal, na.rm = TRUE), "high arousal", "low arousal"))
ggplot(vad_age,aes(x=arousal_level, y = age))+
geom_violin(aes(fill = arousal_level))
cat_vad = hm_data%>%
inner_join(km_vad, by="hmid")%>%
select(hmid,
predicted_category,
subjective_group)
cat_vad_cnt = data.frame(cat_vad%>%
group_by(subjective_group)%>%
dplyr::count(predicted_category))
cat_vad_cnt[,1]=factor(cat_vad_cnt[,1])
head(cat_vad_cnt)
cnt_lst = split(cat_vad_cnt, f=cat_vad_cnt$subjective_group)
cnt_lst
cnt_df = NULL
for(i in 1:3){
cnt_lst[[i]]$proportion = round(cnt_lst[[i]]$n/sum(cnt_lst[[i]]$n),4)
cnt_lst[[i]] = cnt_lst[[i]][,-3]
names(cnt_lst[[i]])[1]="group"
cnt_df = rbind(cnt_df, cnt_lst[[i]])
}
cnt_df$predicted_category = factor(cnt_df$predicted_category, levels = rev(c("achievement", "affection", "bonding", "enjoy_the_moment","leisure","nature","exercise")))
ggplot(data = cnt_df, aes(x=predicted_category,y=proportion,fill=group))+
geom_bar(stat = "identity")+
facet_wrap(as.formula("~group"), ncol = 3)+
coord_flip()+
labs(title = "Proportion of Categories in Each Group", x = "Predicted Category", y = "Proportion")
vad_bag = data.frame(bag_of_words)%>%
inner_join(km_vad, by = "hmid")%>%
select(hmid, word, subjective_group)
wc_vad = data.frame(vad_bag%>%
group_by(subjective_group)%>%
dplyr::count(word))
wc_vad_lists = pre_split(wc_vad)
op = sublist(wc_vad_lists)
op_df_lst = lapply(op, as.data.frame)
op_df_lst[[1]]$dicts = row.names(op_df_lst[[1]])
op_df_lst
op_df = NULL
for (i in 1:3){
op_df_lst[[i]]$dicts = row.names(op_df_lst[[i]])
op_df_lst[[i]]$group = i
names(op_df_lst[[i]])[1]="proportion"
op_df_lst[[i]]$proportion = round(op_df_lst[[i]]$proportion/sum(op_df_lst[[i]]$proportion),digits = 4)
op_df = rbind(op_df,op_df_lst[[i]])
}
op_df_lst
op_df
op_df$group=as.factor(op_df$group)
op_df$dicts = factor(op_df$dicts,levels = rev(names(comp_output[[1]][[1]])))
ggplot(data = op_df,aes(x=dicts,y=proportion, fill=group))+
geom_bar(stat = "identity")+
facet_wrap(as.formula("~group"), ncol = 3)+
coord_flip()+
labs(title = "Proportion of Topic Words in Each Group", x = "Topic", y = "Relative Frequency")
ggplot(data = cnt_df, aes(x=predicted_category,y=proportion,fill=group))+
geom_bar(stat = "identity")+
facet_wrap(as.formula("~group"), ncol = 3)+
# coord_flip()+
labs(title = "Proportion of Categories in Each Group", x = "Predicted Category", y = "Proportion")
ggplot(data = cnt_df, aes(x=predicted_category,y=proportion,fill=group))+
geom_bar(stat = "identity")+
facet_wrap(as.formula("~group"), ncol = 3)+
coord_flip()+
labs(title = "Proportion of Categories in Each Group", x = "Predicted Category", y = "Proportion")
low_val = head(hm_data[order(hm_data$valency,decreasing = FALSE),]$original_hm,10)
low_val
# happiness arise from pain
high_val=  head(hm_data[order(hm_data$valency,decreasing = TRUE),]$original_hm,10)
high_val
#real happiness
low_aro = head(hm_data[order(hm_data$arousal,decreasing = FALSE),]$original_hm,10)
low_aro
low_val = head(hm_data[order(hm_data$valency,decreasing = FALSE),]$original_hm,10)
low_val
# happiness arise from pain
low_val = head(hm_data[order(hm_data$valency,decreasing = FALSE),]$original_hm,5)
low_val
# happiness arise from pain
high_val=  head(hm_data[order(hm_data$valency,decreasing = TRUE),]$original_hm,5)
high_val
#real happiness
low_aro = head(hm_data[order(hm_data$arousal,decreasing = FALSE),]$original_hm,5)
low_aro
head(hm_data[order(hm_data$valency,decreasing = FALSE),]$predicted_category,5)
low_val = head(hm_data[order(hm_data$valency,decreasing = FALSE),]$original_hm,5)
low_val
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=dominance), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>4 & valency <8),aes(x=valency, y=dominance),method = "lm", formula = y ~ x, size = 1)
ggplot(data=hm_data)+
geom_jitter(aes(x=valency, y=arousal), size =0.1, color = "antiquewhite4")+
stat_smooth(data=subset(hm_data, valency>4 & valency <8),aes(x=valency, y=arousal),method = "lm", formula = y ~ x + I(x^2), size = 1)
#produce a word cloud
set.seed(1)
wordcloud2(data = word_count, shape = 'star', size = 0.6, backgroundColor = "lightsalmon" )
atrs <- c("gender", "marital", "parenthood", "reflection_period")
temp0 = list()
sql_cat = list()
for (i in 1:length(atrs)){
sql_cat[[i]] = pred_cat%>%
dplyr::count(!!as.symbol(atrs[i]),predicted_category)%>%
group_by(!!as.symbol(atrs[i]),predicted_category)
}
sql_cat[[5]] = pred_cat%>%
dplyr::count(country,predicted_category)%>%
group_by(country,predicted_category)%>%
filter(country %in% c("USA","IND"))
atrs[5]="country"
names(sql_cat)=atrs
divi <-function(vec,df){
vec1 = as.vector(vec)
if (as.character(vec1[1])==as.character(df[1,1])){
vec1[3]=as.numeric(vec1[3])/as.numeric(df[1,2])
}
else{
vec1[3]=as.numeric(vec1[3])/as.numeric(df[2,2])
}
return(vec1[3])
}
cnt_to_prop<-function(df){
df = data.frame(df)
df_sum = df%>%
group_by(!!as.symbol(names(df)[1]))%>%
dplyr::summarise(total = sum(n, na.rm = TRUE))
df_sum = data.frame(df_sum)
props = round(as.numeric(apply(df,1,divi,df_sum)),digits = 4)
df[,3] = props
names(df)[3]="proportion"
return(df)
}
gen = data.frame(sql_cat[[1]])
#try
ttt = data.frame(data.frame(sql_cat[[1]])%>%
group_by(gender)%>%
dplyr::summarise(total = sum(n)))
cnt_to_prop(data.frame(sql_cat[[1]]))
bi_cat<-function(df){
df = cnt_to_prop(df)
ggplot(data=df, aes(x=!!as.symbol(names(df)[2]),y=!!as.symbol(names(df)[3])))+
geom_bar(aes(fill=!!as.symbol(names(df)[1])), position = "dodge", stat="identity")+
# theme(axis.text.x = element_text(angle = 60, hjust = 1))+
coord_flip()
}
cat_plt = lapply(sql_cat[1:4], FUN = bi_cat )
ggarrange(cat_plt[[1]],cat_plt[[2]], cat_plt[[3]], cat_plt[[4]], plt, common.legend=FALSE,legend = 'right', nrow=2, ncol=2)
atrs <- c("gender", "marital", "parenthood", "reflection_period")
temp0 = list()
sql_cat = list()
for (i in 1:length(atrs)){
sql_cat[[i]] = pred_cat%>%
dplyr::count(!!as.symbol(atrs[i]),predicted_category)%>%
group_by(!!as.symbol(atrs[i]),predicted_category)
}
sql_cat[[5]] = pred_cat%>%
dplyr::count(country,predicted_category)%>%
group_by(country,predicted_category)%>%
filter(country %in% c("USA","IND"))
atrs[5]="country"
names(sql_cat)=atrs
divi <-function(vec,df){
vec1 = as.vector(vec)
if (as.character(vec1[1])==as.character(df[1,1])){
vec1[3]=as.numeric(vec1[3])/as.numeric(df[1,2])
}
else{
vec1[3]=as.numeric(vec1[3])/as.numeric(df[2,2])
}
return(vec1[3])
}
cnt_to_prop<-function(df){
df = data.frame(df)
df_sum = df%>%
group_by(!!as.symbol(names(df)[1]))%>%
dplyr::summarise(total = sum(n, na.rm = TRUE))
df_sum = data.frame(df_sum)
props = round(as.numeric(apply(df,1,divi,df_sum)),digits = 4)
df[,3] = props
names(df)[3]="proportion"
return(df)
}
gen = data.frame(sql_cat[[1]])
#try
ttt = data.frame(data.frame(sql_cat[[1]])%>%
group_by(gender)%>%
dplyr::summarise(total = sum(n)))
bi_cat<-function(df){
df = cnt_to_prop(df)
ggplot(data=df, aes(x=!!as.symbol(names(df)[2]),y=!!as.symbol(names(df)[3])))+
geom_bar(aes(fill=!!as.symbol(names(df)[1])), position = "dodge", stat="identity")+
# theme(axis.text.x = element_text(angle = 60, hjust = 1))+
coord_flip()
}
cat_plt = lapply(sql_cat[1:4], FUN = bi_cat )
ggarrange(cat_plt[[1]],cat_plt[[2]], cat_plt[[3]], cat_plt[[4]], plt, common.legend=FALSE,legend = 'right', nrow=2, ncol=2)
## install and load libraries
packages.used=c("tidyverse", "tidytext","DT", "scales", "wordcloud2", "gridExtra", "ngram",
"shiny", "igraph", "ggraph", "wordcloud", "RColorBrewer", "plyr", "Hmisc",
"plotrix", "ggpubr", "ggfortify")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load libraries
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
library(igraph)
library(ggraph)
library(wordcloud)
library(RColorBrewer)
library(plyr)
library(Hmisc)
library(plotrix)
library(ggpubr)
library(ggfortify)
# load data for use
hm_data <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
urlfile2<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/vad.csv'
vad_data <- read_csv(urlfile2)
urladr<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/topic_dict/'
# combine two data sets and keep the columns needed
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(hmid,
wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
predicted_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
# Create a bag of words using the text data
bag_of_words <-  hm_data %>%
unnest_tokens(word, text)
word_count <- bag_of_words %>%
dplyr::count(word, sort = TRUE)
#produce a word cloud
set.seed(1)
wordcloud2(data = word_count, shape = 'star', size = 0.6, backgroundColor = "lightsalmon" )
# urladr<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/topic_dict/'
dict_vec = c("entertainment", "exercise", "family", "food", "people", "pets","school", "shopping", "work")
load_dict<-function(dict){
return(read.csv(paste(urladr,dict,"-dict.csv", sep = ""),header = FALSE))
}
dict_list = apply(matrix(dict_vec,nrow=length(dict_vec),ncol=1),1,load_dict)
dict_list = plyr::alply(matrix(dict_vec,nrow=length(dict_vec),ncol=1),1,load_dict)
names(dict_list) = dict_vec
txt = as.vector(hm_data$text)
txt = paste(txt, collapse = " ")
wd = strsplit(txt, split = " ")[[1]]
txt_table = table(wd)
txt_df = as.data.frame(txt_table)
count_key<-function(key, cnt, txt_df){
if (key %in% txt_df[,1]){
return(txt_df[which(txt_df[,1]==key),2])
}
else{
return(0)
}
}
count_dict<-function(df, txt_df){
cnt = 0
cnt_vec = apply(as.matrix(df), 1, count_key, cnt, txt_df)
return(sum(cnt_vec))
}
dict_count = sort(sapply(dict_list, FUN = count_dict, txt_df), decreasing = TRUE)
dict_expand = as.data.frame(rep(names(dict_count),dict_count))
names(dict_expand)="words"
dict_expand$words <- factor(dict_expand$words, levels = rev(names(dict_count)))
ggplot(data = dict_expand)+
geom_bar(aes(x=words),fill = "darkorchid1")+
labs(x="Dictionary", y="Frequency", title = "Frequency of Words in Each Topic")+
coord_flip()
atrs <- c("gender", "marital", "parenthood", "reflection_period")
temp5 = list()
for(i in 1:length(atrs)){
temp5[[i]] <- bag_of_words %>%
dplyr::count(!!as.symbol(atrs[i]),word) %>%
group_by(!!as.symbol(atrs[i])) %>%
mutate(cnt = n) %>%
select(-n)
# spread(!!as.symbol(atrs[i]),value)
}
temp5[[5]] <- bag_of_words%>%
dplyr::count(country,word) %>%
group_by(country) %>%
filter(country %in% c("USA","IND"))%>%
mutate(cnt = n) %>%
select(-n)
atrs = c(atrs, "country")
names(temp5) = atrs
#temp5 is a list of 4 dataframes counting words in each group
pre_split<-function(df){
return(split(df[,2:3],f=df[,1]))
}
#split a dataframe into a list of 2 dataframes
atr_lists=lapply(temp5, FUN = pre_split)
#atr_lists is a list of 4 lists of 2 dataframes counting words in each group
comp_dict<-function(df){
txt_df = df
dict_cnt = sort(sapply(dict_list, FUN = count_dict, as.data.frame(txt_df)), decreasing = TRUE)
return(dict_cnt)
}
sublist<-function(lst){
dict_cnt_l = lapply(lst, FUN = comp_dict)
return(dict_cnt_l)
}
comp_output = lapply(atr_lists, FUN = sublist)
tblst_to_df<-function(tblst){
nm= NA
df1=as.data.frame(rep(names(tblst[[1]]),tblst[[1]]))
names(df1)="dicts"
df1$gp = names(tblst)[1]
df2=as.data.frame(rep(names(tblst[[2]]),tblst[[2]]))
names(df2)="dicts"
df2$gp = names(tblst)[2]
df = rbind(df1, df2)
if(names(tblst)[1]=="f"){
nm=atrs[1]
}
else if(names(tblst)[1]=="married"){
nm=atrs[2]
}
else if(names(tblst)[1]=="n"){
nm=atrs[3]
}
else if(names(tblst)[1]=="hours_24"){
nm=atrs[4]
}
else if(names(tblst)[1]=="IND"){
nm=atrs[5]
}
names(df)[2]=nm
return(df)
}
comp_dict_plot<-function(lst2){
df_mix = tblst_to_df(lst2)
df_mix$dicts = factor(df_mix$dicts,levels = rev(names(comp_output[[1]][[1]])))
ggplot(data = df_mix)+
geom_bar(aes(x=dicts, fill=!!as.symbol(names(df_mix)[2])))+
facet_wrap(as.formula(paste("~", names(df_mix)[2])), ncol = 2, scales = "free")+
coord_flip()+
labs(title = "Frequency of Words in Each Topic", x = "Dictionary", y = "Frequency")+
scale_fill_manual(values=c("#CC6666", "#66CC99"))
}
dict_plt = lapply(comp_output[1:4], FUN = comp_dict_plot)
dict_plt
# ggarrange(dict_plt[[1]],dict_plt[[2]], dict_plt[[3]], dict_plt[[4]], plt, common.legend=FALSE,legend = 'right', nrow=2, ncol=2)
